# Frontend Integration Guide: VoiceLink Transcript Feature

## ‚úÖ AUDIO FILE SERVING IMPLEMENTATION STATUS

### **Current Progress**:
‚úÖ **Backend file mapping system implemented**  
‚úÖ **Audio files properly stored and indexed**  
‚úÖ **File serving endpoint added to routes**  
‚ùå **File serving endpoint not accessible (404 errors)**  

### **Issue Identified**:
The backend has been updated with:
- File mapping system that tracks meeting_id ‚Üí actual filename 
- File serving endpoint `/api/v1/files/{meeting_id}`
- Proper CORS headers and content-type detection
- Existing audio files properly mapped on server start

**However**: The file serving endpoint returns 404 errors, indicating a routing configuration issue.

### **Log Evidence**:
```
INFO:api.routes_fixed:Mapped existing file: meet_20250802_104630_4cd90495 -> 20250802_104630_meet_20250802_104630_4cd90495.wav
INFO:api.routes_fixed:Mapped existing file: meet_20250802_105810_ee4e4f31 -> 20250802_105810_meet_20250802_105810_ee4e4f31.wav
INFO:api.routes_fixed:Mapped existing file: meet_20250802_105838_44e08ded -> 20250802_105838_meet_20250802_105838_44e08ded.mp3
INFO:api.routes_fixed:Mapped existing file: meet_20250802_110021_c3e059f3 -> 20250802_110021_meet_20250802_110021_c3e059f3.wav
INFO:api.routes_fixed:Mapped existing file: meet_20250802_113152_b3518dc0 -> 20250802_113152_meet_20250802_113152_b3518dc0.wav
```

### **Next Steps for Backend**:
The audio file serving functionality has been implemented but requires debugging the route registration. Files are available and mapped correctly.

---

## üö® TRANSCRIPT FEATURE STATUS: ‚úÖ WORKING

The backend transcript feature is **100% working** but the frontend is not using the correct API endpoints. The frontend currently shows "No Transcript Available" because it's not calling the right endpoint or handling the response correctly.

---

## üìã **Required Frontend Changes**

### **Problem**: 
- Frontend shows "No Transcript Available" 
- Backend has transcript data available
- Missing API integration in the frontend

### **Solution**: 
Update the frontend to use the correct API endpoints and display the transcript data.

---

## üîå **API Endpoints to Use**

### **Base URL**: `http://localhost:8000/api/v1`

### **1. Get Meeting Details**
```http
GET /api/v1/meetings/{meeting_id}
```

**Response Example**:
```json
{
  "meeting_id": "meet_20250802_115644_ca592f95",
  "title": "Enhanced Meeting from test_meeting.wav",
  "status": "completed",
  "participants": [],
  "start_time": "2025-08-02T11:56:44.521821",
  "end_time": "2025-08-02T11:56:44.521834",
  "recording_url": "/files/meet_20250802_115644_ca592f95",
  "transcript": "SPEAKER_00: Let's start the sprint planning meeting for this week.\\nSPEAKER_00: I think we should focus on the API redesign and authentication system.\\nSPEAKER_00: The authentication middleware needs to be updated to handle JWT tokens properly.",
  "ai_summary": "Enhanced audio processing completed for test_meeting.wav. Real processing succeeded.",
  "action_items": ["Review enhanced transcript", "Check processing results"],
  "description": "Meeting automatically created from uploaded audio file: test_meeting.wav using enhanced processing.",
  "created_at": "2025-08-02T11:56:44.521834"
}
```

### **2. Get Detailed Transcript (MAIN ENDPOINT)**
```http
GET /api/v1/meetings/{meeting_id}/transcript
```

**Response Example**:
```json
{
  "meeting_id": "meet_20250802_115644_ca592f95",
  "title": "Enhanced Meeting from test_meeting.wav",
  "transcript": {
    "full_text": "SPEAKER_00: Let's start the sprint planning meeting for this week.\\nSPEAKER_00: I think we should focus on the API redesign and authentication system.\\nSPEAKER_00: The authentication middleware needs to be updated to handle JWT tokens properly.",
    "segments": [
      {
        "text": "Let's start the sprint planning meeting for this week.",
        "start_time": 0,
        "end_time": 2.666666666666667,
        "duration": 2.666666666666667,
        "speaker_id": "SPEAKER_00",
        "confidence": 0.85,
        "language": "en",
        "real_transcription": false
      },
      {
        "text": "I think we should focus on the API redesign and authentication system.",
        "start_time": 3.1666666666666667,
        "end_time": 7.166666666666667,
        "duration": 4.000000000000001,
        "speaker_id": "SPEAKER_00",
        "confidence": 0.95,
        "language": "en",
        "real_transcription": false
      },
      {
        "text": "The authentication middleware needs to be updated to handle JWT tokens properly.",
        "start_time": 7.666666666666668,
        "end_time": 10,
        "duration": 2.333333333333332,
        "speaker_id": "SPEAKER_00",
        "confidence": 1.05,
        "language": "en",
        "real_transcription": false
      }
    ],
    "total_segments": 3,
    "total_duration": 10,
    "speakers_detected": 1,
    "processing_method": "enhanced_fallback"
  },
  "speakers": [
    {
      "speaker_id": "SPEAKER_00",
      "segments": [
        {
          "text": "Let's start the sprint planning meeting for this week.",
          "timestamp": "00:00:00",
          "confidence": 0.85,
          "duration": 2.666666666666667
        },
        {
          "text": "I think we should focus on the API redesign and authentication system.",
          "timestamp": "00:00:03",
          "confidence": 0.95,
          "duration": 4.000000000000001
        },
        {
          "text": "The authentication middleware needs to be updated to handle JWT tokens properly.",
          "timestamp": "00:00:07",
          "confidence": 1.05,
          "duration": 2.333333333333332
        }
      ],
      "total_speaking_time": 10.0,
      "segment_count": 3
    }
  ],
  "meeting_info": {
    "status": "completed",
    "start_time": "2025-08-02T11:56:44.521821",
    "duration_minutes": 10,
    "participants": []
  },
  "generated_at": "2025-08-02T11:56:44.521834",
  "source_file": "test_meeting.wav",
  "enhanced_processing": true
}
```

---

## üíª **Frontend Implementation Code**

### **React/TypeScript Example**:

```typescript
// Type definitions
interface TranscriptSegment {
  text: string;
  start_time: number;
  end_time: number;
  duration: number;
  speaker_id: string;
  confidence: number;
  language: string;
}

interface TranscriptData {
  full_text: string;
  segments: TranscriptSegment[];
  total_segments: number;
  total_duration: number;
  speakers_detected: number;
}

interface TranscriptResponse {
  meeting_id: string;
  title: string;
  transcript: TranscriptData;
  speakers: any[];
  meeting_info: {
    status: string;
    start_time: string;
    duration_minutes: number;
    participants: any[];
  };
}

// API call function
const fetchMeetingTranscript = async (meetingId: string): Promise<TranscriptResponse> => {
  const response = await fetch(`http://localhost:8000/api/v1/meetings/${meetingId}/transcript`);
  
  if (!response.ok) {
    throw new Error(`Failed to fetch transcript: ${response.status}`);
  }
  
  return response.json();
};

// React component
const MeetingTranscript: React.FC<{ meetingId: string }> = ({ meetingId }) => {
  const [transcript, setTranscript] = useState<TranscriptResponse | null>(null);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState<string | null>(null);

  useEffect(() => {
    const loadTranscript = async () => {
      try {
        setLoading(true);
        const data = await fetchMeetingTranscript(meetingId);
        setTranscript(data);
        setError(null);
      } catch (err) {
        setError(err instanceof Error ? err.message : 'Failed to load transcript');
        setTranscript(null);
      } finally {
        setLoading(false);
      }
    };

    if (meetingId) {
      loadTranscript();
    }
  }, [meetingId]);

  if (loading) {
    return <div>Loading transcript...</div>;
  }

  if (error) {
    return <div>Error: {error}</div>;
  }

  if (!transcript || !transcript.transcript.full_text) {
    return (
      <div>
        <h3>No Transcript Available</h3>
        <p>The transcript for this meeting is not available or may still be processing.</p>
      </div>
    );
  }

  return (
    <div>
      <h3>Meeting Transcript</h3>
      <div>
        <h4>Full Transcript:</h4>
        <div style={{ whiteSpace: 'pre-wrap', padding: '10px', background: '#f5f5f5' }}>
          {transcript.transcript.full_text}
        </div>
      </div>
      
      <div>
        <h4>Transcript Segments:</h4>
        {transcript.transcript.segments.map((segment, index) => (
          <div key={index} style={{ margin: '10px 0', padding: '10px', border: '1px solid #ddd' }}>
            <div><strong>{segment.speaker_id}</strong> ({segment.timestamp})</div>
            <div>{segment.text}</div>
            <div><small>Confidence: {segment.confidence.toFixed(2)}</small></div>
          </div>
        ))}
      </div>
    </div>
  );
};
```

### **JavaScript/Fetch Example**:
```javascript
// Simple JavaScript implementation
async function loadMeetingTranscript(meetingId) {
  try {
    const response = await fetch(`http://localhost:8000/api/v1/meetings/${meetingId}/transcript`);
    
    if (!response.ok) {
      throw new Error(`HTTP error! status: ${response.status}`);
    }
    
    const data = await response.json();
    
    // Display the transcript
    displayTranscript(data);
    
  } catch (error) {
    console.error('Error loading transcript:', error);
    document.getElementById('transcript-container').innerHTML = `
      <h3>Error Loading Transcript</h3>
      <p>Failed to load transcript: ${error.message}</p>
    `;
  }
}

function displayTranscript(data) {
  const container = document.getElementById('transcript-container');
  
  if (!data.transcript || !data.transcript.full_text) {
    container.innerHTML = `
      <h3>No Transcript Available</h3>
      <p>The transcript for this meeting is not available or may still be processing.</p>
    `;
    return;
  }
  
  container.innerHTML = `
    <h3>Meeting Transcript</h3>
    <div>
      <h4>Full Text:</h4>
      <div style="white-space: pre-wrap; padding: 10px; background: #f5f5f5;">
        ${data.transcript.full_text}
      </div>
    </div>
    <div>
      <h4>Segments (${data.transcript.total_segments} total):</h4>
      ${data.transcript.segments.map(segment => `
        <div style="margin: 10px 0; padding: 10px; border: 1px solid #ddd;">
          <div><strong>${segment.speaker_id}</strong> (${formatTime(segment.start_time)})</div>
          <div>${segment.text}</div>
          <div><small>Confidence: ${segment.confidence.toFixed(2)}</small></div>
        </div>
      `).join('')}
    </div>
  `;
}

function formatTime(seconds) {
  const mins = Math.floor(seconds / 60);
  const secs = Math.floor(seconds % 60);
  return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
}
```

---

## üîß **Debugging Steps**

### **1. Check Current Frontend API Calls**
Look for any existing API calls in the transcript component and verify:
- Is it calling the correct URL?
- Is it using the right HTTP method (GET)?
- Is it handling the response properly?

### **2. Test API Directly**
Use browser developer tools or curl to test:
```bash
# Test if meetings exist
curl http://localhost:8000/api/v1/meetings

# Test specific transcript endpoint
curl http://localhost:8000/api/v1/meetings/MEETING_ID_HERE/transcript
```

### **3. Common Issues to Check**
- ‚ùå Wrong API endpoint URL
- ‚ùå Missing error handling
- ‚ùå Not checking if transcript data exists
- ‚ùå CORS issues (should be resolved with current backend setup)
- ‚ùå Incorrect meeting ID being passed

---

## ‚úÖ **Expected Results**

After implementing these changes, the frontend should:

1. **Show transcript data** instead of "No Transcript Available"
2. **Display formatted transcript** with speaker information
3. **Show transcript segments** with timing information
4. **Handle loading states** properly
5. **Show error messages** when API calls fail

---

## üöÄ **Next Steps**

1. **Implement the API calls** using the provided code examples
2. **Update the transcript component** to use the `/transcript` endpoint
3. **Test with a real meeting ID** (upload an audio file to get one)
4. **Verify the display** shows the transcript content properly

The backend is ready and working - just need the frontend to connect to it! üéØ
